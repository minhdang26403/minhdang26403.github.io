<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> An Engineer's Guide to Deep Learning Optimizers | Dang Truong </title> <meta name="author" content="Dang Truong"> <meta name="description" content="A deep-dive into deep learning optimizers where we trace the evolution from SGD to Momentum and finally to Adam."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://minhdang26403.github.io/blog/2025/optimizers/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Dang</span> Truong </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">bookshelf </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">An Engineer's Guide to Deep Learning Optimizers</h1> <p class="post-meta"> Created on October 21, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning,</a>   <a href="/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> optimization,</a>   <a href="/blog/tag/adam"> <i class="fa-solid fa-hashtag fa-sm"></i> adam,</a>   <a href="/blog/tag/sgd"> <i class="fa-solid fa-hashtag fa-sm"></i> sgd,</a>   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a>   ·   <a href="/blog/category/deep-learning"> <i class="fa-solid fa-tag fa-sm"></i> deep-learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="part-1-the-impossible-dream-and-the-noisy-workaround">Part 1: The Impossible Dream and the Noisy Workaround</h2> <h3 id="introduction-the-mountain-in-the-fog">Introduction: The Mountain in the Fog</h3> <p>If you’re an engineer, you’ve been trained to find the “best” solution. So when you start with deep learning, you hit a simple problem: we have a loss function, and we just want to find the lowest point. This is a solved problem, right?</p> <p>Well, no. The “loss landscape” of a neural network isn’t a smooth, convex bowl. It’s a nightmarish, high-dimensional mountain range with a million peaks, valleys, and saddle points, and it’s all shrouded in a dense fog.</p> <ul> <li> <strong>High-Dimensional:</strong> You don’t have two parameters (x, y) to tune. You have 175 billion.</li> <li> <strong>Non-Convex:</strong> There are countless “local minima” (valleys) that <em>look</em> like the lowest point but aren’t.</li> <li> <strong>Stochastic:</strong> You’re in a fog. You can’t even <em>see</em> the whole mountain range. You can only get a <em>noisy guess</em> of the slope from your immediate surroundings.</li> </ul> <p>This is the real job of an optimizer: not to find the “perfect” global minimum, but to find <em>any</em> wide, flat, “good enough” valley, as quickly as possible, without falling off a cliff.</p> <p>This is the story of how we built a better “hiker” for this insane terrain. It starts with the textbook idea and its first, critical, systems-level failure.</p> <hr> <h3 id="the-baseline-gradient-descent-gd">The Baseline: Gradient Descent (GD)</h3> <p>Gradient Descent (also called “Batch” Gradient Descent) is the simple, textbook algorithm you learn in your first machine learning class.</p> <p><strong>The Idea:</strong> “Before I take a single step, I will poll <em>every single person</em> (data point) in the entire dataset. I’ll average all their opinions of which way is ‘downhill’ to get a perfect, noise-free gradient, and <em>then</em> I’ll take one, confident step in that exact direction.”</p> <p>The update rule is just: \(W_{\text{new}} = W_{\text{old}} - \eta \cdot \nabla L(W)\)</p> <p>Where $\nabla L(W)$ is the gradient (derivative) of the loss, calculated over <strong>all</strong> training examples.</p> <p><strong>The “Why Not”: The Systems-Level Dealbreaker</strong></p> <p>This sounds great, but it’s a systems-level catastrophe.</p> <ul> <li> <strong>Problem:</strong> You have a 10TB dataset of images.</li> <li> <strong>The GD approach:</strong> You must run a full forward and backward pass over all <em>10 terabytes</em> of data just to compute a <em>single</em> gradient.</li> <li> <strong>The Result:</strong> You will update your weights <em>once</em> every few hours. Your model will be “training” but going nowhere.</li> </ul> <p>It’s computationally pure, but practically impossible. The bottleneck isn’t the math; it’s the I/O and compute time of using the entire dataset for every single step.</p> <hr> <h3 id="the-workaround-stochastic-gradient-descent-sgd">The Workaround: Stochastic Gradient Descent (SGD)</h3> <p>This is the first brilliant, practical “patch” that makes deep learning possible.</p> <p><strong>The Idea:</strong> “Polling the entire dataset is a waste of time. I’ll just grab a <em>small, random handful</em> (a “mini-batch”) of 64 data points, ask them which way is downhill, and take a quick, messy, ‘good enough’ step in that direction.”</p> <p><strong>The “Why”: The Two Big Wins</strong></p> <p>SGD solves the first problem but introduces a new one (which we’ll fix later).</p> <p><strong>1. It’s Fast. Mind-Bogglingly Fast.</strong> This is the main point. In the time it takes GD to compute <em>one</em> perfect step, SGD has already taken 10,000 “noisy” steps and is 90% of the way to the valley. It’s the difference between planning a perfect cross-country road trip and just getting in the car and driving west.</p> <p><strong>2. The “Bug” is a Feature: Noise is a Regularizer</strong> This is the non-obvious magic of SGD. The gradient from a mini-batch is <em>noisy</em>. It’s not the “true” gradient. This means the optimizer’s path is a chaotic, zig-zagging mess.</p> <p>It turns out this is exactly what we want.</p> <p>In a non-convex landscape, the “perfect” minimum is often a very <em>sharp, narrow</em> valley. This is called <strong>overfitting</strong>—the model has perfectly memorized the training data but will fail on new data.</p> <p>The noise in SGD acts like a drunk hiker. It’s too shaky and chaotic to fall into those narrow, sharp valleys. It prefers to “bounce around” until it settles into a <strong>wide, flat valley</strong>. A flat valley is a <em>generalizable</em> solution—it means that even if the new data is slightly different, the loss is still low.</p> <p><strong>The New Problem</strong></p> <p>But that “zig-zag” is still a problem.</p> <ol> <li>If the valley is a steep, narrow ravine (like in the image above), SGD will spend all its time bouncing off the walls, making very slow progress down the <em>actual</em> slope.</li> <li>If the valley is a <em>very flat</em> plateau, the gradients are tiny, and the “noisy” steps are almost zero. SGD just sits there, barely moving.</li> </ol> <p>This is our next bug. We need a way to <strong>dampen the zig-zagging</strong> and <strong>build up speed (momentum)</strong> in consistent directions.</p> <p>…and that’s exactly what our first “patch,” SGD with Momentum, is designed to fix.</p> <h2 id="part-2-the-snowball-patch-sgd-with-momentum">Part 2: The Snowball Patch (SGD with Momentum)</h2> <h3 id="the-baseline-the-drunk-hiker-sgd">The Baseline: The “Drunk Hiker” (SGD)</h3> <p>In Part 1, we established our baseline: Stochastic Gradient Descent (SGD). It’s the “drunk hiker” in the foggy, non-convex mountain range of our loss landscape.</p> <ul> <li> <strong>The Good:</strong> It’s fast (uses mini-batches) and its “noisy” path is a feature, helping it bounce out of sharp, “overfitting” minima and find the wide, generalizable valleys.</li> <li> <strong>The Bad:</strong> That same noise is a critical bug. It creates two huge problems: <ol> <li> <strong>Oscillation:</strong> In a steep, narrow ravine, the hiker just bounces from wall to wall, making almost no <em>downhill</em> progress.</li> <li> <strong>Stalling:</strong> On a long, flat plateau, the gradient (slope) is tiny. The hiker takes tiny, hesitant steps and barely moves at all, stalling the training.</li> </ol> </li> </ul> <p>We need a fix. We need to give our hiker a way to “average out” the noise from the zig-zagging and “build up speed” on the flats. This fix is called <strong>Momentum</strong>.</p> <hr> <h3 id="the-first-fix-sgd-with-momentum-the-snowball">The First Fix: SGD with Momentum (The Snowball)</h3> <p><strong>The Idea:</strong> Instead of taking a step based <em>only</em> on the current (noisy) gradient, we take a step based on a <strong>moving average</strong> of all past gradients.</p> <p>Think of it as replacing our lightweight hiker with a heavy, unstoppable snowball.</p> <p>At each step, we do two things:</p> <ol> <li>We apply friction to the “snowball” (the old momentum), reducing its speed by a fraction (e.g., 10%).</li> <li>We add the new gradient (the “push” from the new mini-batch) to the snowball.</li> </ol> <p>In code, this “velocity” vector $v$ is updated like this (where $\beta$ is the momentum term, usually 0.9):</p> <p>\(v_t = (\beta \cdot v_{t-1}) + g_t\) \(W_{\text{new}} = W_{\text{old}} - \eta \cdot v_t\)</p> <p>(Note: You’ll see different forms of this equation, but they all share this core idea: the current step is a combination of the previous step and the new gradient.)</p> <p>This one simple change brilliantly solves <em>both</em> of our problems.</p> <h4 id="1-the-fix-for-oscillation-the-smoother">1. The Fix for Oscillation: The “Smoother”</h4> <p>How does this stop the “zig-zag”?</p> <p>Imagine our optimizer is in that narrow ravine. The “bounces” are just noisy gradients pointing in opposite directions.</p> <ul> <li> <strong>Step 1 Gradient ($g_1$):</strong> <code class="language-plaintext highlighter-rouge">[+10, -0.1]</code> (Bounces right, moves slightly down)</li> <li> <strong>Step 2 Gradient ($g_2$):</strong> <code class="language-plaintext highlighter-rouge">[-10, -0.1]</code> (Bounces left, moves slightly down)</li> </ul> <p><strong>Vanilla SGD</strong> would just move right, then left, and barely go anywhere.</p> <p><strong>Momentum</strong> averages them:</p> <ul> <li> <strong>Step 1 Velocity ($v_1$):</strong> <code class="language-plaintext highlighter-rouge">[+10, -0.1]</code> </li> <li> <strong>Step 2 Velocity ($v_2$):</strong> <code class="language-plaintext highlighter-rouge">v_2 = (0.9 * [+10, -0.1]) + [-10, -0.1] = [+9, -0.09] + [-10, -0.1] = [-1, -0.19]</code> </li> </ul> <p>Look at that! The horizontal part (the <code class="language-plaintext highlighter-rouge">+10</code> and <code class="language-plaintext highlighter-rouge">-10</code>) has <strong>averaged out</strong> and cancelled. The vertical part (the <code class="language-plaintext highlighter-rouge">-0.1</code> and <code class="language-plaintext highlighter-rouge">-0.1</code>) has <strong>accumulated</strong>.</p> <p>The snowball’s momentum in the zig-zag directions dies, while its momentum in the consistent “downhill” direction builds. The path becomes dramatically smoother.</p> <h4 id="2-the-fix-for-stalling-the-accelerator">2. The Fix for Stalling: The “Accelerator”</h4> <p>This is the “snowball” effect.</p> <p>Now, imagine our optimizer is on that long, flat plateau. The gradient is tiny but consistent.</p> <ul> <li> <strong>Gradient at all steps:</strong> <code class="language-plaintext highlighter-rouge">[-0.01]</code> (a tiny, but consistent push)</li> </ul> <p><strong>Vanilla SGD</strong> would just take tiny steps: <code class="language-plaintext highlighter-rouge">-0.01</code>, <code class="language-plaintext highlighter-rouge">-0.01</code>, <code class="language-plaintext highlighter-rouge">-0.01</code>… It would take 100 steps just to move a total of 1.0.</p> <p><strong>Momentum</strong> builds up speed:</p> <ul> <li> <strong>$v_1$:</strong> <code class="language-plaintext highlighter-rouge">-0.01</code> </li> <li> <strong>$v_2$:</strong> $(0.9 \cdot -0.01) + -0.01 = -0.019$</li> <li> <strong>$v_3$:</strong> $(0.9 \cdot -0.019) + -0.01 = -0.0271$</li> <li> <strong>$v_4$:</strong> $(0.9 \cdot -0.0271) + -0.01 = -0.03439$</li> </ul> <p>The velocity is <em>accelerating</em>. The snowball is picking up speed, allowing the optimizer to “shoot” across the flat plateau and converge much faster.</p> <hr> <h3 id="the-new-problem">The New Problem</h3> <p>So, we’re done, right? SGD with Momentum is great. It’s fast, and it’s smooth.</p> <p>We’ve solved the big problems, but we’ve exposed two new, more subtle ones.</p> <ol> <li> <p><strong>The “Cold-Start” Problem:</strong> What is the velocity $v_0$ at the very beginning of training? It’s <code class="language-plaintext highlighter-rouge">0</code>. Because our “snowball” starts with zero momentum, it takes several steps to “warm up” and get to a reasonable speed. This means the first few iterations are artificially slow and hesitant. This is the <strong>initialization bias</strong>.</p> </li> <li> <p><strong>The “One-Size-Fits-All” Problem:</strong> We are still using <em>one</em> learning rate $\eta$ for all 175 billion parameters. This is a huge issue. What if the loss landscape for your <code class="language-plaintext highlighter-rouge">Weight_1</code> is a gentle, flat plain, but the landscape for <code class="language-plaintext highlighter-rouge">Weight_1000</code> is a treacherous, spiky mountain?</p> <ul> <li> <code class="language-plaintext highlighter-rouge">Weight_1</code> needs a <em>big</em> learning rate to move faster.</li> <li> <code class="language-plaintext highlighter-rouge">Weight_1000</code> needs a <em>tiny</em> learning rate to avoid exploding.</li> </ul> <p>Our current optimizer gives them both the <em>same</em> learning rate. It’s like forcing our downhill skier and our cross-country skier to use the same pair of skis.</p> </li> </ol> <p>To fix this, we need a way to give every parameter its <em>own</em>, unique, <strong>adaptive learning rate</strong>.</p> <p>And <em>that</em> brings us to the next generation of optimizers… and the clever ideas that led to Adam.</p> <hr> <h2 id="part-3-the-king-of-the-hill-adaptive-moment-estimation">Part 3: The King of the Hill (Adaptive Moment Estimation)</h2> <h3 id="the-story-so-far">The Story So Far</h3> <p>In Part 1, we established that “Batch” Gradient Descent is impossible, so we use <strong>Stochastic Gradient Descent (SGD)</strong>. But SGD, our “drunk hiker,” is noisy. It zig-zags in steep ravines and stalls on flat plains.</p> <p>In Part 2, we added the <strong>Momentum</strong> “patch,” which turns our hiker into a heavy “snowball.” This solves our two problems:</p> <ol> <li> <strong>It smooths out</strong> the zig-zagging by averaging gradients.</li> <li> <strong>It accelerates</strong> across flat plains by building up speed.</li> </ol> <p>But we were left with two new, more subtle bugs in our optimizer:</p> <ol> <li> <strong>The “Cold-Start” Problem:</strong> Our snowball starts with zero velocity. It takes a bunch of steps to “warm up,” making the start of training artificially slow. This is an <strong>initialization bias</strong>.</li> <li> <strong>The “One-Size-Fits-All” Problem:</strong> We’re still using <em>one</em> learning rate $\eta$ for all 175 billion parameters. This is a huge issue. The terrain for <code class="language-plaintext highlighter-rouge">Weight_1</code> might be a flat, gentle plain (needs a <em>big</em> step), while the terrain for <code class="language-plaintext highlighter-rouge">Weight_1000</code> is a spiky, treacherous mountain (needs a <em>tiny</em> step). We’re giving them both the same boot size.</li> </ol> <p>We need an optimizer that can fix <em>both</em>. We need a “snowball” that starts fast and has “adaptive skis” that adjust to the terrain of each parameter.</p> <p>This brings us to <strong>Adam</strong>.</p> <hr> <h3 id="the-final-patch-adam-adaptive-moment-estimation">The Final Patch: Adam (Adaptive Moment Estimation)</h3> <p>The name “Adam” is a spoiler. It stands for <strong>Adaptive Moment Estimation</strong>. It doesn’t just estimate the <em>first</em> moment (the “snowball” velocity). It <em>also</em> estimates the <em>second</em> moment (the “volatility” of the gradient) and uses it to <em>adapt</em> the learning rate.</p> <p>Adam is not a new idea from scratch. It’s the “Avengers Assemble” of optimizers, combining two best-in-class solutions into one algorithm.</p> <h4 id="the-momentum-fix-the-m-in-adam">The Momentum Fix (The “M” in Adam)</h4> <p>This first part of Adam is just SGD with Momentum, but with a fix for the “cold-start” problem.</p> <ul> <li> <strong>The Biased Snowball ($m_t$):</strong> Adam keeps track of the momentum (the first moment) just like before: \(m_t = \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t\)</li> <li> <strong>The “Cold-Start” Bug:</strong> As we said, $m_0$ is initialized to 0. This makes $m_1$, $m_2$, $m_3$, etc., all artificially small. They are <em>biased</em> toward zero.</li> <li> <strong>The Unbiasing Trick:</strong> The Adam authors provided a simple, brilliant fix. They calculate this bias analytically and just divide it out. \(\hat{m}_t = \frac{m_t}{1 - \beta_1^t}\)</li> </ul> <p>Let’s see this in action (with $\beta_1 = 0.9$):</p> <ul> <li> <strong>At Step 1 ($t=1$):</strong> The denominator is $(1 - 0.9^1) = 0.1$. The biased $m_1$ is divided by 0.1 (multiplied by 10), perfectly correcting it.</li> <li> <strong>At Step 500 ($t=500$):</strong> The denominator is $(1 - 0.9^{500})$, which is $\approx 1.0$. The correction <em>automatically fades away</em> and does nothing.</li> </ul> <p>This “bias-corrected” momentum $\hat{m}_t$ is the first half of Adam. It’s a “snowball” that starts at full speed.</p> <h4 id="the-adaptive-fix-the-a-in-adam">The Adaptive Fix (The “A” in Adam)</h4> <p>This is the second, more powerful idea. It solves the “one-size-fits-all” problem.</p> <ul> <li> <strong>The Problem:</strong> We need a <em>per-parameter</em> learning rate. We need to know if the terrain for <code class="language-plaintext highlighter-rouge">Weight_1</code> is flat or spiky.</li> <li> <strong>The Fix (RMSprop):</strong> We can <em>measure</em> the “spikiness” of the terrain by tracking a moving average of the <em>squared gradients</em>. This is the <strong>second moment ($v_t$)</strong>. \(v_t = \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot (g_t)^2\)</li> <li> <strong>Why squared?</strong> Squaring $g_t$ makes it positive. Now, $v_t$ is a measure of “gradient volatility.” <ul> <li>If $v_t$ is <em>large</em>, it means this parameter has huge, spiky gradients. The terrain is treacherous.</li> <li>If $v_t$ is <em>small</em>, it means this parameter has tiny, consistent gradients. The terrain is flat.</li> </ul> </li> <li> <strong>The “Aha!” Moment:</strong> The final Adam update rule is, conceptually: \(W_{\text{new}} = W_{\text{old}} - \alpha \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}\)</li> </ul> <p>Look at that division. We are dividing our “snowball” step ($\hat{m}_t$) by the square root of its “volatility” ($\hat{v}_t$).</p> <p>This gives every single parameter its own learning rate:</p> <ul> <li> <strong>Spiky Terrain (Large $v_t$):</strong> The denominator is <em>big</em>. The step size becomes <em>small</em>. Adam says, “Whoa, be careful on this parameter. Take tiny, safe steps.”</li> <li> <strong>Flat Terrain (Small $v_t$):</strong> The denominator is <em>tiny</em>. The step size is <em>amplified</em>. Adam says, “This parameter is on a boring flat, let’s give it a boost and go faster!”</li> </ul> <p>(And yes, this $v_t$ term is <em>also</em> biased toward zero at the start, so Adam applies the <em>same</em> unbiasing trick to it, giving $\hat{v}_t$).</p> <hr> <h3 id="conclusion-the-king-is-crowned">Conclusion: The King is Crowned</h3> <p>Adam is the default king because it combines both fixes.</p> <ul> <li>It’s a <strong>snowball</strong> (using momentum, $\hat{m}<em>t$) that knows which _direction</em> to go.</li> <li>It has <strong>adaptive skis</strong> (using $\sqrt{\hat{v}<em>t}$) that automatically adjust for the _terrain</em> of <em>every single parameter</em>.</li> <li>It has a <strong>warm-up” pack</strong> (the bias correction) so it can start at full speed from iteration 1.</li> </ul> <p>It solves every major problem we’ve identified. It’s fast, it’s robust, it handles initialization, and it doesn’t need nearly as much “learning rate” tuning.</p> <p>This is, by far, the most common optimizer you’ll see.</p> <p><strong>…But is it perfect?</strong></p> <p>If Adam is so great, why do many state-of-the-art research papers <em>still</em> use plain SGD with Momentum?</p> <p>It turns out, there’s a “Level 3” debate. Some researchers believe that Adam’s adaptive nature, while fast, can sometimes “find” a <em>worse</em> minimum—one that is sharp and doesn’t generalize as well as the wide, flat valleys that the “dumber” SGD + Momentum eventually stumbles into.</p> <p>But for 99% of engineers, Adam is the robust, reliable, and powerful tool that gets the job done.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/ndarray-design/">How to Build a Multi-Dimensional Array by Separating View Logic from Compute Kernels</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/newton-vs-sgd/">Why Not Newton? The Real Reason We're Stuck with SGD for Deep Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/plotly/">a post with plotly.js</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Dang Truong. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>